[{"repo": "urllib3/urllib3", "pull_number": 3655, "instance_id": "urllib3__urllib3-3655", "issue_numbers": ["3649"], "base_commit": "4587fd6d477f22022be08de597c3a5acd5185c0a", "patch": "diff --git a/changelog/3649.bugfix.rst b/changelog/3649.bugfix.rst\nnew file mode 100644\nindex 0000000000..f0ce5fd815\n--- /dev/null\n+++ b/changelog/3649.bugfix.rst\n@@ -0,0 +1,2 @@\n+Fixed redirect handling in ``urllib3.PoolManager`` when an integer is passed\n+for the retries parameter.\n\\ No newline at end of file\ndiff --git a/src/urllib3/poolmanager.py b/src/urllib3/poolmanager.py\nindex 5763fea808..28ec82f016 100644\n--- a/src/urllib3/poolmanager.py\n+++ b/src/urllib3/poolmanager.py\n@@ -203,20 +203,18 @@ def __init__(\n         **connection_pool_kw: typing.Any,\n     ) -> None:\n         super().__init__(headers)\n+        # PoolManager handles redirects itself in PoolManager.urlopen().\n+        # It always passes redirect=False to the underlying connection pool to\n+        # suppress per-pool redirect handling. If the user supplied a non-Retry\n+        # value (int/bool/etc) for retries and we let the pool normalize it\n+        # while redirect=False, the resulting Retry object would have redirect\n+        # handling disabled, which can interfere with PoolManager's own\n+        # redirect logic. Normalize here so redirects remain governed solely by\n+        # PoolManager logic.\n         if \"retries\" in connection_pool_kw:\n             retries = connection_pool_kw[\"retries\"]\n             if not isinstance(retries, Retry):\n-                # When Retry is initialized, raise_on_redirect is based\n-                # on a redirect boolean value.\n-                # But requests made via a pool manager always set\n-                # redirect to False, and raise_on_redirect always ends\n-                # up being False consequently.\n-                # Here we fix the issue by setting raise_on_redirect to\n-                # a value needed by the pool manager without considering\n-                # the redirect boolean.\n-                raise_on_redirect = retries is not False\n-                retries = Retry.from_int(retries, redirect=False)\n-                retries.raise_on_redirect = raise_on_redirect\n+                retries = Retry.from_int(retries)\n                 connection_pool_kw = connection_pool_kw.copy()\n                 connection_pool_kw[\"retries\"] = retries\n         self.connection_pool_kw = connection_pool_kw\n", "test_patch": "diff --git a/test/with_dummyserver/test_poolmanager.py b/test/with_dummyserver/test_poolmanager.py\nindex 7f163ab330..8b9ae652cc 100644\n--- a/test/with_dummyserver/test_poolmanager.py\n+++ b/test/with_dummyserver/test_poolmanager.py\n@@ -26,8 +26,12 @@ def setup_class(cls) -> None:\n         cls.base_url = f\"http://{cls.host}:{cls.port}\"\n         cls.base_url_alt = f\"http://{cls.host_alt}:{cls.port}\"\n \n-    def test_redirect(self) -> None:\n-        with PoolManager() as http:\n+    @pytest.mark.parametrize(\n+        \"pool_manager_kwargs\",\n+        ({}, {\"retries\": None}, {\"retries\": 1}, {\"retries\": Retry(1)}),\n+    )\n+    def test_redirect(self, pool_manager_kwargs: dict[str, typing.Any]) -> None:\n+        with PoolManager(**pool_manager_kwargs) as http:\n             r = http.request(\n                 \"GET\",\n                 f\"{self.base_url}/redirect\",\n@@ -46,8 +50,12 @@ def test_redirect(self) -> None:\n             assert r.status == 200\n             assert r.data == b\"Dummy server!\"\n \n-    def test_redirect_twice(self) -> None:\n-        with PoolManager() as http:\n+    @pytest.mark.parametrize(\n+        \"pool_manager_kwargs\",\n+        ({}, {\"retries\": None}, {\"retries\": 2}, {\"retries\": Retry(2)}),\n+    )\n+    def test_redirect_twice(self, pool_manager_kwargs: dict[str, typing.Any]) -> None:\n+        with PoolManager(**pool_manager_kwargs) as http:\n             r = http.request(\n                 \"GET\",\n                 f\"{self.base_url}/redirect\",\n", "problem_statement": "Redirects do not work on a PoolManager configured with custom retries\n### Subject\n\nThis started happening with the 2.5.0 release, as a result of changes made in https://github.com/urllib3/urllib3/commit/f05b1329126d5be6de501f9d1e3e36738bc08857. If you create a `PoolManager` with an explicit number of retries given as an integer, then redirects get disabled. I believe this is not intended.\n\n### Environment\n\nDescribe your environment.\n\n```\nOS macOS-15.5-arm64-arm-64bit\nPython 3.11.10\nOpenSSL 3.5.0 8 Apr 2025\nurllib3 2.5.0\n```\n\n### Steps to Reproduce\n\nRun the following in a Python repl:\n\n```python\nimport urllib3\nhttp = urllib3.PoolManager(retries=10)\nr = http.request(\"GET\", \"https://httpbin.org/redirect/1\")\n```\n\n### Expected Behavior\n\nA response is returned.\n\n### Actual Behavior\n\nThe request raises the following exception:\n\n```\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='httpbin.org', port=443): Max retries exceeded with url: https://httpbin.org/redirect/1 (Caused by ResponseError('too many redirects'))\n```\n\n### Additional details\n\nThe error only occurs when the pool is initialized with an integer number of retries. Both not passing `retries` and passing it set to a `Retry` instance leave redirects enabled and working as expected. Adding a `retries` argument to the `request()` call also works fine, even if an integer is passed as its value.\n", "hints_text": "", "created_at": "2025-08-10T10:21:10Z", "version": "2.5"}, {"repo": "urllib3/urllib3", "pull_number": 3620, "instance_id": "urllib3__urllib3-3620", "issue_numbers": ["3615"], "base_commit": "11661e9bb4278e43d081f47a516e287a928c2206", "patch": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml\nindex f6d60bb839..a1310c0035 100644\n--- a/.github/workflows/ci.yml\n+++ b/.github/workflows/ci.yml\n@@ -58,6 +58,11 @@ jobs:\n             os: ubuntu-24.04\n             experimental: false\n             nox-session: test_integration\n+          # Test with 3.12.2 for https://github.com/urllib3/urllib3/pull/3620 patch\n+          - python-version: \"3.12.2\"\n+            os: ubuntu-24.04\n+            experimental: false\n+            nox-session: test-3.12\n           # pypy\n           - python-version: \"pypy-3.10\"\n             os: ubuntu-24.04\ndiff --git a/changelog/3615.bugfix.rst b/changelog/3615.bugfix.rst\nnew file mode 100644\nindex 0000000000..af11d62032\n--- /dev/null\n+++ b/changelog/3615.bugfix.rst\n@@ -0,0 +1,1 @@\n+Fixed incorrect `CONNECT` statement when using an IPv6 proxy with `connection_from_host`. Previously would not be wrapped in `[]`.\ndiff --git a/src/urllib3/connection.py b/src/urllib3/connection.py\nindex a178d17ed6..8082387d94 100644\n--- a/src/urllib3/connection.py\n+++ b/src/urllib3/connection.py\n@@ -232,45 +232,94 @@ def set_tunnel(\n         super().set_tunnel(host, port=port, headers=headers)\n         self._tunnel_scheme = scheme\n \n-    if sys.version_info < (3, 11, 4):\n-\n-        def _tunnel(self) -> None:\n-            _MAXLINE = http.client._MAXLINE  # type: ignore[attr-defined]\n-            connect = b\"CONNECT %s:%d HTTP/1.0\\r\\n\" % (  # type: ignore[str-format]\n-                self._tunnel_host.encode(\"ascii\"),  # type: ignore[union-attr]\n-                self._tunnel_port,\n-            )\n-            headers = [connect]\n-            for header, value in self._tunnel_headers.items():  # type: ignore[attr-defined]\n-                headers.append(f\"{header}: {value}\\r\\n\".encode(\"latin-1\"))\n-            headers.append(b\"\\r\\n\")\n-            # Making a single send() call instead of one per line encourages\n-            # the host OS to use a more optimal packet size instead of\n-            # potentially emitting a series of small packets.\n-            self.send(b\"\".join(headers))\n-            del headers\n-\n-            response = self.response_class(self.sock, method=self._method)  # type: ignore[attr-defined]\n-            try:\n-                (version, code, message) = response._read_status()  # type: ignore[attr-defined]\n-\n-                if code != http.HTTPStatus.OK:\n-                    self.close()\n-                    raise OSError(f\"Tunnel connection failed: {code} {message.strip()}\")\n-                while True:\n-                    line = response.fp.readline(_MAXLINE + 1)\n-                    if len(line) > _MAXLINE:\n-                        raise http.client.LineTooLong(\"header line\")\n-                    if not line:\n-                        # for sites which EOF without sending a trailer\n-                        break\n-                    if line in (b\"\\r\\n\", b\"\\n\", b\"\"):\n-                        break\n+    if sys.version_info < (3, 11, 9) or ((3, 12) <= sys.version_info < (3, 12, 3)):\n+        # Taken from python/cpython#100986 which was backported in 3.11.9 and 3.12.3.\n+        # When using connection_from_host, host will come without brackets.\n+        def _wrap_ipv6(self, ip: bytes) -> bytes:\n+            if b\":\" in ip and ip[0] != b\"[\"[0]:\n+                return b\"[\" + ip + b\"]\"\n+            return ip\n+\n+        if sys.version_info < (3, 11, 9):\n+            # `_tunnel` copied from 3.11.13 backporting\n+            # https://github.com/python/cpython/commit/0d4026432591d43185568dd31cef6a034c4b9261\n+            # and https://github.com/python/cpython/commit/6fbc61070fda2ffb8889e77e3b24bca4249ab4d1\n+            def _tunnel(self) -> None:\n+                _MAXLINE = http.client._MAXLINE  # type: ignore[attr-defined]\n+                connect = b\"CONNECT %s:%d HTTP/1.0\\r\\n\" % (  # type: ignore[str-format]\n+                    self._wrap_ipv6(self._tunnel_host.encode(\"ascii\")),  # type: ignore[union-attr]\n+                    self._tunnel_port,\n+                )\n+                headers = [connect]\n+                for header, value in self._tunnel_headers.items():  # type: ignore[attr-defined]\n+                    headers.append(f\"{header}: {value}\\r\\n\".encode(\"latin-1\"))\n+                headers.append(b\"\\r\\n\")\n+                # Making a single send() call instead of one per line encourages\n+                # the host OS to use a more optimal packet size instead of\n+                # potentially emitting a series of small packets.\n+                self.send(b\"\".join(headers))\n+                del headers\n+\n+                response = self.response_class(self.sock, method=self._method)  # type: ignore[attr-defined]\n+                try:\n+                    (version, code, message) = response._read_status()  # type: ignore[attr-defined]\n+\n+                    if code != http.HTTPStatus.OK:\n+                        self.close()\n+                        raise OSError(\n+                            f\"Tunnel connection failed: {code} {message.strip()}\"\n+                        )\n+                    while True:\n+                        line = response.fp.readline(_MAXLINE + 1)\n+                        if len(line) > _MAXLINE:\n+                            raise http.client.LineTooLong(\"header line\")\n+                        if not line:\n+                            # for sites which EOF without sending a trailer\n+                            break\n+                        if line in (b\"\\r\\n\", b\"\\n\", b\"\"):\n+                            break\n+\n+                        if self.debuglevel > 0:\n+                            print(\"header:\", line.decode())\n+                finally:\n+                    response.close()\n+\n+        elif (3, 12) <= sys.version_info < (3, 12, 3):\n+            # `_tunnel` copied from 3.12.11 backporting\n+            # https://github.com/python/cpython/commit/23aef575c7629abcd4aaf028ebd226fb41a4b3c8\n+            def _tunnel(self) -> None:  # noqa: F811\n+                connect = b\"CONNECT %s:%d HTTP/1.1\\r\\n\" % (  # type: ignore[str-format]\n+                    self._wrap_ipv6(self._tunnel_host.encode(\"idna\")),  # type: ignore[union-attr]\n+                    self._tunnel_port,\n+                )\n+                headers = [connect]\n+                for header, value in self._tunnel_headers.items():  # type: ignore[attr-defined]\n+                    headers.append(f\"{header}: {value}\\r\\n\".encode(\"latin-1\"))\n+                headers.append(b\"\\r\\n\")\n+                # Making a single send() call instead of one per line encourages\n+                # the host OS to use a more optimal packet size instead of\n+                # potentially emitting a series of small packets.\n+                self.send(b\"\".join(headers))\n+                del headers\n+\n+                response = self.response_class(self.sock, method=self._method)  # type: ignore[attr-defined]\n+                try:\n+                    (version, code, message) = response._read_status()  # type: ignore[attr-defined]\n+\n+                    self._raw_proxy_headers = http.client._read_headers(response.fp)  # type: ignore[attr-defined]\n \n                     if self.debuglevel > 0:\n-                        print(\"header:\", line.decode())\n-            finally:\n-                response.close()\n+                        for header in self._raw_proxy_headers:\n+                            print(\"header:\", header.decode())\n+\n+                    if code != http.HTTPStatus.OK:\n+                        self.close()\n+                        raise OSError(\n+                            f\"Tunnel connection failed: {code} {message.strip()}\"\n+                        )\n+\n+                finally:\n+                    response.close()\n \n     def connect(self) -> None:\n         self.sock = self._new_conn()\n", "test_patch": "diff --git a/test/with_dummyserver/test_socketlevel.py b/test/with_dummyserver/test_socketlevel.py\nindex 89db60b422..2968669fab 100644\n--- a/test/with_dummyserver/test_socketlevel.py\n+++ b/test/with_dummyserver/test_socketlevel.py\n@@ -22,6 +22,7 @@\n from test import LONG_TIMEOUT, SHORT_TIMEOUT, notWindows, resolvesLocalhostFQDN\n from threading import Event\n from unittest import mock\n+from urllib.parse import urlparse\n \n import pytest\n import trustme\n@@ -1289,7 +1290,7 @@ def echo_socket_handler(listener: socket.socket) -> None:\n             r = conn.urlopen(\"GET\", url, retries=0)\n             assert r.status == 200\n \n-    def test_connect_ipv6_addr(self) -> None:\n+    def test_connect_ipv6_addr_from_host(self) -> None:\n         ipv6_addr = \"2001:4998:c:a06::2:4008\"\n \n         def echo_socket_handler(listener: socket.socket) -> None:\n@@ -1329,13 +1330,75 @@ def echo_socket_handler(listener: socket.socket) -> None:\n \n         with proxy_from_url(base_url, cert_reqs=\"NONE\") as proxy:\n             url = f\"https://[{ipv6_addr}]\"\n+\n+            # Try with connection_from_host\n+            parsed_request_url = urlparse(url)\n+\n+            conn = proxy.connection_from_host(\n+                scheme=parsed_request_url.scheme.lower(),\n+                host=parsed_request_url.hostname,\n+                port=parsed_request_url.port,\n+            )\n+            try:\n+                with pytest.warns(InsecureRequestWarning):\n+                    r = conn.urlopen(\"GET\", url, retries=0)\n+                assert r.status == 200\n+            except MaxRetryError:\n+                pytest.fail(\n+                    \"Invalid IPv6 format in HTTP CONNECT request when using connection_from_host\"\n+                )\n+\n+    def test_connect_ipv6_addr_from_url(self) -> None:\n+        ipv6_addr = \"2001:4998:c:a06::2:4008\"\n+\n+        def echo_socket_handler(listener: socket.socket) -> None:\n+            sock = listener.accept()[0]\n+\n+            buf = b\"\"\n+            while not buf.endswith(b\"\\r\\n\\r\\n\"):\n+                buf += sock.recv(65536)\n+            s = buf.decode(\"utf-8\")\n+\n+            if s.startswith(f\"CONNECT [{ipv6_addr}]:443\"):\n+                sock.send(b\"HTTP/1.1 200 Connection Established\\r\\n\\r\\n\")\n+                ssl_sock = original_ssl_wrap_socket(\n+                    sock,\n+                    server_side=True,\n+                    keyfile=DEFAULT_CERTS[\"keyfile\"],\n+                    certfile=DEFAULT_CERTS[\"certfile\"],\n+                )\n+                buf = b\"\"\n+                while not buf.endswith(b\"\\r\\n\\r\\n\"):\n+                    buf += ssl_sock.recv(65536)\n+\n+                ssl_sock.send(\n+                    b\"HTTP/1.1 200 OK\\r\\n\"\n+                    b\"Content-Type: text/plain\\r\\n\"\n+                    b\"Content-Length: 2\\r\\n\"\n+                    b\"Connection: close\\r\\n\"\n+                    b\"\\r\\n\"\n+                    b\"Hi\"\n+                )\n+                ssl_sock.close()\n+            else:\n+                sock.close()\n+\n+        self._start_server(echo_socket_handler)\n+        base_url = f\"http://{self.host}:{self.port}\"\n+\n+        with proxy_from_url(base_url, cert_reqs=\"NONE\") as proxy:\n+            url = f\"https://[{ipv6_addr}]\"\n+\n+            # Try with connection_from_url\n             conn = proxy.connection_from_url(url)\n             try:\n                 with pytest.warns(InsecureRequestWarning):\n                     r = conn.urlopen(\"GET\", url, retries=0)\n                 assert r.status == 200\n             except MaxRetryError:\n-                pytest.fail(\"Invalid IPv6 format in HTTP CONNECT request\")\n+                pytest.fail(\n+                    \"Invalid IPv6 format in HTTP CONNECT request when using connection_from_url\"\n+                )\n \n     @pytest.mark.parametrize(\"target_scheme\", [\"http\", \"https\"])\n     def test_https_proxymanager_connected_to_http_proxy(\n", "problem_statement": "IPv6 with a proxy fails with Python3.9\n### Subject\n\nTake the following mitmproxy docker compose in a IPv6 environment\n```\nservices:\n    mitmproxy:\n        image: mitmproxy/mitmproxy\n        command: mitmdump --set ssl_insecure --set allow_hosts=\"::/0\" --set proxyauth=\"user:pass\" --\n        ports:\n            - \"8080:8080\"\n        networks:\n            - mitmproxy_network\n\nnetworks:\n  mitmproxy_network:\n    enable_ipv6: true\n```\n\nI take the following test script\n```\nimport urllib3\nimport requests\n\nprint(urllib3.__version__)\nprint(requests.__version__)\n\nr = requests.get(\n    \"https://[some:ipv6:ipaddress:1::10]:1234/uri/path/redacted\",  # with some ipv6 address\n    auth=(\"admin\", \"password\"),\n    proxies={\n        \"http\": \"http://user:pass@[fdac:a8f0:d40b:1::2]:8080\",  # Using an IPv6 Proxy address.\n        \"https\": \"http://user:pass@[fdac:a8f0:d40b:1::2]:8080\"  # Can grab this via docker inspect\n    },\n    verify=False\n)\n\nprint(r.status_code)\nprint(r.text)\n```\n\nThis fails with \n```\nTraceback (most recent call last):\n... (truncated)\nrequests.exceptions.ProxyError: HTTPSConnectionPool(host='some:ipv6:ipaddress:1::10', port=1234): Max retries exceeded with url: /uri/path/redacted (Caused by ProxyError('Unable to connect to proxy', OSError('Tunnel connection failed: 400 Bad Request')))\n```\n\nLooking through the code, I found that https://github.com/urllib3/urllib3/blob/main/src/urllib3/connection.py#L235 will have different proxy behavior with < 3.11.4\n\nHowever, this code path with IPv6 eventually calls this `CONNECT` command incorrectly.\n```\n(Pdb) connect\nb'CONNECT some:ipv6:ipaddress:1::10:1234 HTTP/1.0\\r\\n'\n```\n\nIn Python 3.13, this is correctly called, since it has the IPv6 handler in the python builtin library\nhttps://github.com/python/cpython/blob/3.9/Lib/http/client.py#L912\n```\n(Pdb) connect\nb'CONNECT [some:ipv6:ipaddress:1::10]:1234 HTTP/1.1\\r\\n'\n```\n\nOther notes\n- Using a url like https://google.com works fine.\n- Using CURL works fine -\n```\ncurl -x http://user:pass@[fdac:a8f0:d40b:1::2]:8080 -6 -k -u  admin:password https://[myipv6address]:1234/uri/path/redacted\n```\n\nI have not personally tested with 3.10 or  < 3.11.4, but I would assume they would have similar issues.\n\n### Environment\n\n>>> print(\"OS\", platform.platform())\nOS Linux-5.4.17-2136.343.5.1.el8uek.x86_64-x86_64-with-glibc2.36\n>>> print(\"Python\", platform.python_version())\nPython 3.9.22\n>>> print(ssl.OPENSSL_VERSION)\nOpenSSL 3.0.16 11 Feb 2025\n>>> print(\"urllib3\", urllib3.__version__)\nurllib3 2.4.0\n\n### Steps to Reproduce\n\nWhat I did\n- Run the mitmproxy compose file\n- You'll need an ipv6 enabled web server... (I'll try to see if I can make a single compose file to do everything)\n- Run a python3.9 docker image interactively  `sudo docker run --network ${USER}_mitmproxy_network --entrypoint /bin/bash -it python:3.9`\n    - you could mount a dir or something here to make it easier. Otherwise, I installed vim and installed `pip install requests==2.32.3`\n    - Then ran the script\n\n### Expected Behavior\n\nI would expect it to not fail during the TUNNEL connection phase.\n\n### Actual Behavior\n\nRaises an exception for ProxyError\n\n", "hints_text": "", "created_at": "2025-06-13T00:38:30Z", "version": "2.4"}, {"repo": "urllib3/urllib3", "pull_number": 3611, "instance_id": "urllib3__urllib3-3611", "issue_numbers": ["3610"], "base_commit": "47ac841d9f38c78fc92a5de90aea2bf556549669", "patch": "diff --git a/changelog/3610.feature.rst b/changelog/3610.feature.rst\nnew file mode 100644\nindex 0000000000..0e72dbee85\n--- /dev/null\n+++ b/changelog/3610.feature.rst\n@@ -0,0 +1,2 @@\n+Add support for the ``compression.zstd`` module that is new in Python 3.14.\n+See `PEP 784 <https://peps.python.org/pep-0784/>`_ for more information.\n\\ No newline at end of file\ndiff --git a/docs/advanced-usage.rst b/docs/advanced-usage.rst\nindex f6ab70bd7d..a5cfdb74aa 100644\n--- a/docs/advanced-usage.rst\n+++ b/docs/advanced-usage.rst\n@@ -561,11 +561,14 @@ Zstandard Encoding\n `Zstandard <https://datatracker.ietf.org/doc/html/rfc8878>`_\n is a compression algorithm created by Facebook with better compression\n than brotli, gzip and deflate (see `benchmarks <https://facebook.github.io/zstd/#benchmarks>`_)\n-and is supported by urllib3 if the `zstandard package <https://pypi.org/project/zstandard/>`_ is installed.\n+and is supported by urllib3 in Python 3.14+ using the `compression.zstd <https://peps.python.org/pep-0784/>`_ standard library module\n+and for Python 3.13 and earlier if the `zstandard package <https://pypi.org/project/zstandard/>`_ is installed.\n You may also request the package be installed via the ``urllib3[zstd]`` extra:\n \n .. code-block:: bash\n \n+    # This is only necessary on Python 3.13 and earlier.\n+    # Otherwise zstandard support is included in the Python standard library.\n     $ python -m pip install urllib3[zstd]\n \n .. note::\ndiff --git a/pyproject.toml b/pyproject.toml\nindex 2d18b808ad..60fce65dcc 100644\n--- a/pyproject.toml\n+++ b/pyproject.toml\n@@ -44,6 +44,10 @@ brotli = [\n   \"brotli>=1.0.9; platform_python_implementation == 'CPython'\",\n   \"brotlicffi>=0.8.0; platform_python_implementation != 'CPython'\"\n ]\n+# Once we drop support for Python 3.13 this extra can be removed.\n+# We'll need a deprecation period for the 'zstandard' module support\n+# so that folks using Python without the 'compression.zstd' module\n+# compiled will know to start doing so (although it'll likely be rare).\n zstd = [\n   \"zstandard>=0.18.0\",\n ]\ndiff --git a/src/urllib3/response.py b/src/urllib3/response.py\nindex 66c6a687ec..399a72a098 100644\n--- a/src/urllib3/response.py\n+++ b/src/urllib3/response.py\n@@ -26,23 +26,6 @@\n except ImportError:\n     brotli = None\n \n-try:\n-    import zstandard as zstd\n-except (AttributeError, ImportError, ValueError):  # Defensive:\n-    HAS_ZSTD = False\n-else:\n-    # The package 'zstandard' added the 'eof' property starting\n-    # in v0.18.0 which we require to ensure a complete and\n-    # valid zstd stream was fed into the ZstdDecoder.\n-    # See: https://github.com/urllib3/urllib3/pull/2624\n-    _zstd_version = tuple(\n-        map(int, re.search(r\"^([0-9]+)\\.([0-9]+)\", zstd.__version__).groups())  # type: ignore[union-attr]\n-    )\n-    if _zstd_version < (0, 18):  # Defensive:\n-        HAS_ZSTD = False\n-    else:\n-        HAS_ZSTD = True\n-\n from . import util\n from ._base_connection import _TYPE_BODY\n from ._collections import HTTPHeaderDict\n@@ -163,11 +146,15 @@ def flush(self) -> bytes:\n             return b\"\"\n \n \n-if HAS_ZSTD:\n+try:\n+    # Python 3.14+\n+    from compression import zstd  # type: ignore[import-not-found] # noqa: F401\n+\n+    HAS_ZSTD = True\n \n     class ZstdDecoder(ContentDecoder):\n         def __init__(self) -> None:\n-            self._obj = zstd.ZstdDecompressor().decompressobj()\n+            self._obj = zstd.ZstdDecompressor()\n \n         def decompress(self, data: bytes) -> bytes:\n             if not data:\n@@ -175,15 +162,53 @@ def decompress(self, data: bytes) -> bytes:\n             data_parts = [self._obj.decompress(data)]\n             while self._obj.eof and self._obj.unused_data:\n                 unused_data = self._obj.unused_data\n-                self._obj = zstd.ZstdDecompressor().decompressobj()\n+                self._obj = zstd.ZstdDecompressor()\n                 data_parts.append(self._obj.decompress(unused_data))\n             return b\"\".join(data_parts)\n \n         def flush(self) -> bytes:\n-            ret = self._obj.flush()  # note: this is a no-op\n             if not self._obj.eof:\n                 raise DecodeError(\"Zstandard data is incomplete\")\n-            return ret\n+            return b\"\"\n+\n+except ImportError:\n+    try:\n+        # Python 3.13 and earlier require the 'zstandard' module.\n+        import zstandard as zstd\n+\n+        # The package 'zstandard' added the 'eof' property starting\n+        # in v0.18.0 which we require to ensure a complete and\n+        # valid zstd stream was fed into the ZstdDecoder.\n+        # See: https://github.com/urllib3/urllib3/pull/2624\n+        _zstd_version = tuple(\n+            map(int, re.search(r\"^([0-9]+)\\.([0-9]+)\", zstd.__version__).groups())  # type: ignore[union-attr]\n+        )\n+        if _zstd_version < (0, 18):  # Defensive:\n+            raise ImportError(\"zstandard module doesn't have eof\")\n+    except (AttributeError, ImportError, ValueError):  # Defensive:\n+        HAS_ZSTD = False\n+    else:\n+        HAS_ZSTD = True\n+\n+        class ZstdDecoder(ContentDecoder):  # type: ignore[no-redef]\n+            def __init__(self) -> None:\n+                self._obj = zstd.ZstdDecompressor().decompressobj()\n+\n+            def decompress(self, data: bytes) -> bytes:\n+                if not data:\n+                    return b\"\"\n+                data_parts = [self._obj.decompress(data)]\n+                while self._obj.eof and self._obj.unused_data:\n+                    unused_data = self._obj.unused_data\n+                    self._obj = zstd.ZstdDecompressor().decompressobj()\n+                    data_parts.append(self._obj.decompress(unused_data))\n+                return b\"\".join(data_parts)\n+\n+            def flush(self) -> bytes:\n+                ret = self._obj.flush()  # note: this is a no-op\n+                if not self._obj.eof:\n+                    raise DecodeError(\"Zstandard data is incomplete\")\n+                return ret  # type: ignore[no-any-return]\n \n \n class MultiDecoder(ContentDecoder):\ndiff --git a/src/urllib3/util/request.py b/src/urllib3/util/request.py\nindex 94392a13b9..23605c522b 100644\n--- a/src/urllib3/util/request.py\n+++ b/src/urllib3/util/request.py\n@@ -28,12 +28,20 @@\n     pass\n else:\n     ACCEPT_ENCODING += \",br\"\n+\n try:\n-    import zstandard as _unused_module_zstd  # noqa: F401\n-except ImportError:\n-    pass\n-else:\n+    from compression import (  # type: ignore[import-not-found] # noqa: F401\n+        zstd as _unused_module_zstd,\n+    )\n+\n     ACCEPT_ENCODING += \",zstd\"\n+except ImportError:\n+    try:\n+        import zstandard as _unused_module_zstd  # noqa: F401\n+\n+        ACCEPT_ENCODING += \",zstd\"\n+    except ImportError:\n+        pass\n \n \n class _TYPE_FAILEDTELL(Enum):\n", "test_patch": "diff --git a/test/__init__.py b/test/__init__.py\nindex b5eedc72e0..281e4114b5 100644\n--- a/test/__init__.py\n+++ b/test/__init__.py\n@@ -26,9 +26,18 @@\n     brotli = None\n \n try:\n-    import zstandard as _unused_module_zstd  # noqa: F401\n+    # Python 3.14\n+    from compression import (  # type: ignore[import-not-found] # noqa: F401\n+        zstd as _unused_module_zstd,\n+    )\n except ImportError:\n-    HAS_ZSTD = False\n+    # Python 3.13 and earlier require the 'zstandard' module.\n+    try:\n+        import zstandard as _unused_module_zstd  # noqa: F401\n+    except ImportError:\n+        HAS_ZSTD = False\n+    else:\n+        HAS_ZSTD = True\n else:\n     HAS_ZSTD = True\n \n@@ -127,14 +136,15 @@ def notBrotli() -> typing.Callable[[_TestFuncT], _TestFuncT]:\n \n def onlyZstd() -> typing.Callable[[_TestFuncT], _TestFuncT]:\n     return pytest.mark.skipif(\n-        not HAS_ZSTD, reason=\"only run if a python-zstandard library is installed\"\n+        not HAS_ZSTD,\n+        reason=\"only run if a python-zstandard library is installed or Python 3.14 and later\",\n     )\n \n \n def notZstd() -> typing.Callable[[_TestFuncT], _TestFuncT]:\n     return pytest.mark.skipif(\n         HAS_ZSTD,\n-        reason=\"only run if a python-zstandard library is not installed\",\n+        reason=\"only run if a python-zstandard library is not installed or Python 3.13 and earlier\",\n     )\n \n \ndiff --git a/test/test_response.py b/test/test_response.py\nindex 3eec0abaab..9552689f22 100644\n--- a/test/test_response.py\n+++ b/test/test_response.py\n@@ -35,6 +35,14 @@\n from urllib3.util.retry import RequestHistory, Retry\n \n \n+def zstd_compress(data: bytes) -> bytes:\n+    try:\n+        from compression import zstd  # type: ignore[import-not-found] # noqa: F401\n+    except ImportError:\n+        import zstandard as zstd\n+    return zstd.compress(data)  # type: ignore[no-any-return]\n+\n+\n class TestBytesQueueBuffer:\n     def test_single_chunk(self) -> None:\n         buffer = BytesQueueBuffer()\n@@ -411,9 +419,7 @@ def test_decode_brotli_error(self) -> None:\n \n     @onlyZstd()\n     def test_decode_zstd(self) -> None:\n-        import zstandard as zstd\n-\n-        data = zstd.compress(b\"foo\")\n+        data = zstd_compress(b\"foo\")\n \n         fp = BytesIO(data)\n         r = HTTPResponse(fp, headers={\"content-encoding\": \"zstd\"})\n@@ -421,11 +427,9 @@ def test_decode_zstd(self) -> None:\n \n     @onlyZstd()\n     def test_decode_multiframe_zstd(self) -> None:\n-        import zstandard as zstd\n-\n         data = (\n             # Zstandard frame\n-            zstd.compress(b\"foo\")\n+            zstd_compress(b\"foo\")\n             # skippable frame (must be ignored)\n             + bytes.fromhex(\n                 \"50 2A 4D 18\"  # Magic_Number (little-endian)\n@@ -433,7 +437,7 @@ def test_decode_multiframe_zstd(self) -> None:\n                 \"00 00 00 00 00 00 00\"  # User_Data\n             )\n             # Zstandard frame\n-            + zstd.compress(b\"bar\")\n+            + zstd_compress(b\"bar\")\n         )\n \n         fp = BytesIO(data)\n@@ -442,9 +446,7 @@ def test_decode_multiframe_zstd(self) -> None:\n \n     @onlyZstd()\n     def test_chunked_decoding_zstd(self) -> None:\n-        import zstandard as zstd\n-\n-        data = zstd.compress(b\"foobarbaz\")\n+        data = zstd_compress(b\"foobarbaz\")\n \n         fp = BytesIO(data)\n         r = HTTPResponse(\n@@ -475,9 +477,7 @@ def test_decode_zstd_error(self, data: bytes) -> None:\n     @onlyZstd()\n     @pytest.mark.parametrize(\"data\", decode_param_set)\n     def test_decode_zstd_incomplete_preload_content(self, data: bytes) -> None:\n-        import zstandard as zstd\n-\n-        data = zstd.compress(data)\n+        data = zstd_compress(data)\n         fp = BytesIO(data[:-1])\n \n         with pytest.raises(DecodeError):\n@@ -486,9 +486,7 @@ def test_decode_zstd_incomplete_preload_content(self, data: bytes) -> None:\n     @onlyZstd()\n     @pytest.mark.parametrize(\"data\", decode_param_set)\n     def test_decode_zstd_incomplete_read(self, data: bytes) -> None:\n-        import zstandard as zstd\n-\n-        data = zstd.compress(data)\n+        data = zstd_compress(data)\n         fp = BytesIO(data[:-1])  # shorten the data to trigger DecodeError\n \n         # create response object without(!) reading/decoding the content\n@@ -503,9 +501,7 @@ def test_decode_zstd_incomplete_read(self, data: bytes) -> None:\n     @onlyZstd()\n     @pytest.mark.parametrize(\"data\", decode_param_set)\n     def test_decode_zstd_incomplete_read1(self, data: bytes) -> None:\n-        import zstandard as zstd\n-\n-        data = zstd.compress(data)\n+        data = zstd_compress(data)\n         fp = BytesIO(data[:-1])\n \n         r = HTTPResponse(\n@@ -523,9 +519,7 @@ def test_decode_zstd_incomplete_read1(self, data: bytes) -> None:\n     @onlyZstd()\n     @pytest.mark.parametrize(\"data\", decode_param_set)\n     def test_decode_zstd_read1(self, data: bytes) -> None:\n-        import zstandard as zstd\n-\n-        encoded_data = zstd.compress(data)\n+        encoded_data = zstd_compress(data)\n         fp = BytesIO(encoded_data)\n \n         r = HTTPResponse(\n", "problem_statement": "Add support for new Python 3.14 `compression.zstd` module\nThanks to @emmatyping Python now has zstandard support in the standard library \ud83e\udd73 See [PEP 784](https://peps.python.org/pep-0784) for more information. I'm adding preferential support for the `compression.zstd` module over the `zstandard` package from PyPI, one day we'll deprecate our `[zstd]` extra after we drop support for Python 3.13.\n", "hints_text": "", "created_at": "2025-05-20T14:11:15Z", "version": "2.4"}]